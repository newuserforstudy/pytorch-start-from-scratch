{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 pytorch图像变换操作包 torchvision.transforms\n",
    "官网：https://pytorch.org/docs/stable/torchvision/transforms.html  \n",
    "中文参考：https://www.cntofu.com/book/169/docs/1.0/torchvision_transforms.md  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 图像变换操作\n",
    "裁剪:Crop  \n",
    "翻转和旋转:Filp and Rotation  \n",
    "像素值变换  \n",
    "对transforms操作  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 随机裁剪 \n",
    "class torchvision.transforms.RandomCrop(size, padding=None, pad_if_needed=False, fill=0,padding_mode='constant')\n",
    "\n",
    "参数意义：\n",
    "size-(sequence or int)如果是sequence,格式为(h,w)，如果为int只需要一个值，格式为(size,size)  \n",
    "padding-(sequence or int, 可选项)设置填充多少个像素，如果是sequence，sequence格式是2个值(pl2r,pd2u)时，第一个值是左右填充的数量，第二个值是上下填充的数量，sequence格式是4个值(pl,pu,pr,pd)时，左上右下填充的数量；如果是int则上下左右填充的一样。\n",
    "pad_if_needed（boolean）– 如果设置为True，若图片小于目标形状，将进行填充以避免报异常。  \n",
    "fill- (int or tuple)设置填充的数值， 格式为int时各通道都一样，格式为长度为3的元组是表示RGB通道分别的填充值。另外，填充值仅仅下一个参数padding_mode='constant'有效。  \n",
    "padding_mode- 填充的模式。constant模式：常量值填充；edge:图像的边缘最后一个值填充；reflect：以边缘为轴且边缘值除外，反射填充，在[1,2,3,4]左右填充2个元素则变成[3,2,1,2,3,4,3,2]，symmetric：对称填充，在[1,2,3,4]左右填充2个元素则变成[2,1,1,2,3,4,4,3]。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 中心裁剪  \n",
    "class torchvision.transforms.CenterCrop(size)\n",
    "在中心处裁剪PIL图片。\n",
    "\n",
    "参数：\n",
    "size（序列 或 int）– 需要裁剪出的形状。如果size是int，将会裁剪成正方形；如果是形如(h, w)的序列，将会裁剪成矩形。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 随机长宽比裁剪  \n",
    "class torchvision.transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=2)  \n",
    "以随机的形状和长宽比裁剪图片。以随机的形状（默认从原始图片的0.08到1.0) 和随机长宽比（默认从3/4到4/3）裁剪图片。然后调整到指定形状。这一变换通常用于训练Inception网络。    \n",
    "参数：\n",
    "size – 每条边的期望输出形状。  \n",
    "scale – 裁剪原始图片出的形状范围。  \n",
    "ratio – 原始长宽比裁剪出的目标范围。  \n",
    "interpolation –插值方法 默认：PIL.Image.BILINEAR，双线性差值。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 上下左右中心裁剪  \n",
    "class torchvision.transforms.FiveCrop(size)\n",
    "从四角和中心裁剪PIL图片。  \n",
    "参数：\n",
    "size（序列 或 int）– 需要裁剪出的形状。如果size是int，将会裁剪成正方形；如果是序列，如(h, w)，将会裁剪成矩形  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 上下左右中心裁剪后翻转 \n",
    "class torchvision.transforms.TenCrop(size, vertical_flip=False)  \n",
    "将PIL图片以四角和中心裁剪，同时加入翻折版本。（默认以水平的方式翻折）      \n",
    "参数：  \n",
    "size（序列 或 int）– 期望裁剪输出的形状。需要裁剪出的形状。如果size是int，将会裁剪成正方形；如果是序列，如(h, w)，将会裁剪成矩形。  \n",
    "vertical_flip（bool）– 是否用垂直翻折   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2.6 依概率垂直翻转 \n",
    "class torchvision.transforms.RandomVerticalFlip(p=0.5)  \n",
    "以给定的概率随机垂直翻折PIL图片。  \n",
    "\n",
    "参数：\n",
    "p (float) – 翻折图片的概率。默认0.5。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2.7 随机旋转   \n",
    "class torchvision.transforms.RandomRotation(degrees, resample=False, expand=False, center=None)  \n",
    "以指定的角度选装图片。  \n",
    "\n",
    "参数：  \n",
    "degrees（序列 或 float or int）– 旋转角度的随机选取范围。如果degrees是序列（min, max），则从中随机选取；如果是数字，则选择范围是（-degrees, +degrees）。  \n",
    "resample（{PIL.Image.NEAREST , PIL.Image.BILINEAR , PIL.Image.BICUBIC} , 可选) – 可选的重采样滤波器，见filters。如果该选项忽略，或图片模式是“1”或者“P”则设置为PIL.Image.NEAREST。  \n",
    "expand（bool, 可选）– 可选的扩展标志。如果设置为True, 将输出扩展到足够大从而能容纳全图。如果设置为False或不设置，输出图片将和输入同样大。注意expand标志要求 flag assumes rotation around the center and no translation。   \n",
    "center（2-tuple , 可选）– 可选的旋转中心坐标。以左上角为原点计算。默认是图像中心。   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8 重置图像分辨率 \n",
    "class torchvision.transforms.Resize(size, interpolation=2)   \n",
    "将输入PIL图片调整大小到给定形状。  \n",
    "\n",
    "参数：  \n",
    "\n",
    "size（序列 或 int）– 期望输出形状。如果size形如（h, w），输出就以该形状。 如果size是int更短的边将调整为int，即如果高>宽，那么图片将调整为（size * 高 / 宽，size）。  \n",
    "interpolation（int, 可选）– 插值方式。默认采用PIL.Image.BILINEAR。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.9  图像标准化\n",
    "class torchvision.transforms.Normalize(mean, std)    \n",
    "用平均值和标准差标准化输入图片。给定n个通道的平均值(M1,...,Mn)和标准差(S1,..,Sn)，这一变换会在torch.*Tensor的每一个通道上进行标准化，即input[channel] = (input[channel] - mean[channel]) / std[channel]。    \n",
    "\n",
    "参数：\n",
    "mean（序列）– 序列，包含各通道的平均值。  \n",
    "std（序列）– 序列，包含各通道的标准差  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.10  转为tensor\n",
    "class torchvision.transforms.ToTensor  \n",
    "将PIL Image或numpy.ndarray转化成张量。  \n",
    "\n",
    "把PIL图像或[0, 255]范围内的numpy.ndarray（形状(H x W x C)）转化成torch.FloatTensor，张量形状(C x H x W)，范围在[0.0, 1.0]中。输入应是是PIL图像且是模式（L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1）中的一种，或输入是numpy.ndarray且类型为np.uint8。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.11  对图像进行填充  \n",
    "class torchvision.transforms.Pad(padding, fill=0, padding_mode='constant')  \n",
    "对PIL图像的各条边缘进行扩展。  \n",
    "\n",
    "参数：\n",
    "\n",
    "padding（int 或 tuple）– 在每条边上展开的宽度。如果传入的是单个int，就在所有边展开。如果传入长为2的元组，则指定左右和上下的展开宽度。如果传入长为4的元组，则依次指定为左、上、右、下的展开宽度。   \n",
    "fill（int 或 tuple） – 像素填充值。默认是0。如果指定长度为3的元组，表示分别填充R, G, B通道。这个参数仅在padding_mode是‘constant’时指定有效。  \n",
    "padding_mode（str）– 展开类型。应当是‘constant’，‘edge’，‘reflect’或‘symmetric’之一。默认为‘constant’。  \n",
    "constant：用常数扩展，这个值由fill参数指定。  \n",
    "edge：用图像边缘上的指填充。  \n",
    "reflect：以边缘为对称轴进行轴对称填充（边缘值不重复）。 > 例如，在[1, 2, 3, 4]的两边填充2个元素会得到[3, 2, 1, 2, 3, 4, 3, 2]。  \n",
    "symmetric：用图像边缘的反转进行填充（图像的边缘值需要重复）。 > 例如，在[1, 2, 3, 4]的两边填充2个元素会得到[2, 1, 1, 2, 3, 4, 4, 3]。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.12 修改图像的亮度、对比度和饱和度 \n",
    "class torchvision.transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0)  \n",
    "随机改变图片的亮度、对比度和饱和度。  \n",
    "\n",
    "参数：  \n",
    "\n",
    "brightness（float或 float类型元组(min, max)）– 亮度的扰动幅度。brightness_factor从[max(0, 1 - brightness), 1 + brightness]中随机采样产生。应当是非负数。  \n",
    "contrast（float或 float类型元组(min, max)）– 对比度扰动幅度。contrast_factor从[max(0, 1 - contrast), 1 + contrast]中随机采样产生。应当是非负数。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.13 图像转为灰度图 \n",
    "class torchvision.transforms.Grayscale(num_output_channels=1)\n",
    "把图片转换为灰阶。  \n",
    "\n",
    "参数：  \n",
    "  \n",
    "num_output_channels（int，1或3）– 希望得到的图片通道数。  \n",
    "返回：  \n",
    "输入图片的灰阶版本。 - 如果num_output_channels == 1：返回单通道图像；- 如果num_output_channels == 3：返回3通道图像，其中r == g == b。  \n",
    "返回类型：   \n",
    "PIL图像。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.14 线性变换\n",
    "class torchvision.transforms.LinearTransformation(transformation_matrix)  \n",
    "用一个预先准备好的变换方阵对图片张量做变换。    \n",
    "  \n",
    "torch.*Tensor会被transformation_matrix拉平，和变换矩阵做点积后调整到原始张量的形状。  \n",
    "\n",
    "应用：   \n",
    "\n",
    "白化：将数据的分布中心处理到0，计算数据的协方差矩阵。   \n",
    "用np.dot(X.T, X)可以处理到[D x D]的形状，对此做奇异值分解然后传给transformation_matrix即可。   \n",
    "参数：   \n",
    "transformation_matrix（Tensor）– [D x D]的张量，D = C x H x W。   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.15 图像仿射变换  \n",
    "class torchvision.transforms.RandomAffine(degrees, translate=None, scale=None, shear=None, resample=False, fillcolor=0)   \n",
    "保持像素的分布中心不变，对图像做随机仿射变换。    \n",
    "\n",
    "参数：    \n",
    " \n",
    "degrees（序列 或 float 或 int）– 旋转角度的筛选范围。如果是序列（min, max），从中随机均匀采样；如果是数字，则从（-degrees, +degrees）中采样。如果不需要旋转，那么设置为0。  \n",
    "translate（tuple, 可选）– 元组，元素值是水平和垂直平移变换的最大绝对值。例如translate=(a, b)时，水平位移值从 -img_width * a < dx < img_width * a中随机采样得到，垂直位移值从-img_height * b < dy < img_height * b中随机采样得到。默认不做平移变换。  \n",
    "scale（tuple, 可选）– 尺度放缩因子的内区间，如[a, b]，放缩因子scale的随机采样区间为：a <= scale <= b。默认不进行尺度放缩变换。  \n",
    "shear（序列 或 float 或 int, 可选）– 扭曲角度的筛选范围。如果是序列（min, max），从中随机均匀采样；如果是数字，则从（-degrees, +degrees）中采样。默认不会进行扭曲操作。  \n",
    "resample（{PIL.Image.NEAREST , PIL.Image.BILINEAR , PIL.Image.BICUBIC} , 可选）– 可选的重采样滤波器，见filters。如果没有该选项，或者图片模式是“1”或“P”，设置为PIL.Image.NEAREST。  \n",
    "fillcolor（int）– 在输出图片的变换外区域可选地填充颜色。（Pillow>=5.0.0）。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.16 依概率转为灰度图  \n",
    "class torchvision.transforms.RandomGrayscale(p=0.1)  \n",
    "以概率p（默认0.1）将图片随机转化为灰阶图片。  \n",
    "\n",
    "参数：  \n",
    "\n",
    "p（float）–图像转化为灰阶的概率。  \n",
    "返回：  \n",
    "\n",
    "以概率p转换为灰阶，以概率（1-p）不做变换。如果输入图像为1通道，则灰阶版本也是1通道。如果输入图像为3通道，则灰阶版本是3通道，r == g == b。\n",
    "返回类型：  \n",
    "\n",
    "PIL图像。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.17 将数据转为PILImage \n",
    "class torchvision.transforms.ToPILImage(mode=None)  \n",
    "把张量或ndarray转化为PIL图像。  \n",
    "  \n",
    "把形状为C x H x W的torch.*Tensor或者形状为H x W x C的numpy矩阵ndarray转化为PIL图像，保留值的上下界。  \n",
    "\n",
    "参数 ：  \n",
    "\n",
    "mode (PIL.Image mode) – 输入数据的颜色空间或者像素深度（可选）。 如果mode设置为None（默认），按照下面的规则进行处理：  \n",
    "如果输入3通道，mode会设置为RGB。   \n",
    "如果输入4通道，mode会设置为RGBA。   \n",
    "如果输入1通道，mode由数据类型决定(即int，float，short)。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.18 对transforms进行操作    \n",
    "class torchvision.transforms.RandomChoice(transforms)   \n",
    "从列表中随机选择一种变换。  \n",
    "\n",
    "class torchvision.transforms.RandomApply(transforms, p=0.5)  \n",
    "对transforms中的各变换以指定的概率决定是否选择。\n",
    "\n",
    "class torchvision.transforms.RandomOrder(transforms)  \n",
    "以随机的顺序对图片做变换。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.19 通用变换  \n",
    "class torchvision.transforms.Lambda(lambd)  \n",
    "将用户定义的函数用作变换。  \n",
    "\n",
    "参数：  \n",
    "  \n",
    "lambd (函数) – 用于变换的Lambda函数或函数名。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.20 Functional变换\n",
    "functional可以提供了一些更加精细的变换，用于搭建复杂的变换流水线。\n",
    "\n",
    "\n",
    "torchvision.transforms.functional.adjust_brightness(img, brightness_factor)   \n",
    "调整图像亮度。   \n",
    "参数：  \n",
    "img（PIL图像）– 要调整的PIL图像。  \n",
    "brightness_factor（float）– 亮度的调整值，可以是任意非负整数。0表示黑色图像，1表示原始图像，2表示增加到2倍亮度。\n",
    "返回：  \n",
    "调整亮度后的图像   \n",
    "\n",
    "\n",
    "torchvision.transforms.functional.adjust_contrast(img, contrast_factor)   \n",
    "调整图像对比度。  \n",
    "参数：   \n",
    "img（PIL图像）– 要调整的PIL图像。\n",
    "contrast_factor（float）– 对比度的调整幅度，可以是任意非负数。0表示灰阶图片，1表示原始图片，2表示对比度增加到2倍。\n",
    "返回：  \n",
    "调整对比度之后的图像。  \n",
    "更多关于Functional变换的内容参考：   \n",
    "https://www.cntofu.com/book/169/docs/1.0/torchvision_transforms.md    \n",
    "https://pytorch.org/docs/stable/torchvision/transforms.html   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
