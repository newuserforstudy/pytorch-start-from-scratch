{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 什么是迁移学习？\n",
    "参考论文：  \n",
    "http://www.jos.org.cn/jos/ch/reader/view_abstract.aspx?file_no=4631&flag=1    \n",
    "https://journalofbigdata.springeropen.com/articles/10.1186/s40537-016-0043-6  \n",
    "https://ieeexplore.ieee.org/abstract/document/5288526  \n",
    "迁移学习是运用已存有的知识对不同但相关领域问题进行求解的一种新的机器学习方法.  \n",
    "迁移学习的做法：在一个数据集上训练好网络，得到网络参数和预训练模型，直接使用预训练模型在第二个数据集上使用，但是二个数据集必须相关。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 为什么要使用迁移学习？\n",
    "总结原因：  \n",
    "(1) 避免标注大量的训练样本(标注样本非常耗时)  \n",
    "(2) 避免构建自定义神经网络(构建神经网络需要精心模式设计和相关的计算)  \n",
    "(3) 避免长时间的模型训练(迁移学习直接使用预训练的模型，实际中只需要微调)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 pytorch图像处理中有哪些预训练模型？\n",
    "第14节进行过介绍，具体请前往参考。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 pytorch迁移学习入门小案例  \n",
    "实际中就是重写全连接层的部分，然后保持卷积层的权重不变化，训练过程只是进行重写的全连接层参数的训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet() # alexnet网络 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model  # 查看下网络结构 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解释下网络的结构：  \n",
    "1 该网络有3个属性即网络分3个阶段：features、avgpool、classifier   \n",
    "2 第一个部分是卷积部分用于特征提取，第二个部分是维度转换用于连接上下层，第三部分是全连接部分用于分类   \n",
    "3 其他网络结构可以自行分析   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重写全连接层的部分 \n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5, inplace=False),\n",
    "    nn.Linear(in_features=9216, out_features=100, bias=True),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.5, inplace=False),\n",
    "    nn.Linear(in_features=100, out_features=100, bias=True),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(in_features=100, out_features=2, bias=True)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=100, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model  # 再来看一下网络的结构 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  如何设置只训练重写的全连接层参数呢？\n",
    "第一步：for param in model.parameters():param.requires_grad = False  \n",
    "第二步：重写全连接层   \n",
    "第三步：optimizer = optim.Adam(model.classifier.parameters(),lr=0.01)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 迁移学习实现猫狗分类 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 导入需要的模块\n",
    "from torchvision import models\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from torch.optim import sgd, adam\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomCrop((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomCrop((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/content/drive/My Drive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDogProcessor(data.Dataset):\n",
    "    def __init__(self, mode, directory):\n",
    "        self.mode = mode\n",
    "        self.list_img = []\n",
    "        self.list_label = []\n",
    "        self.data_size = 0\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            self.transform = transform_train\n",
    "            directory = directory + \"/sdh_train/\"\n",
    "            for file in os.listdir(directory):\n",
    "                self.list_img.append(directory + file)\n",
    "                self.data_size += 1\n",
    "                name = file.split(sep=\".\")\n",
    "                if name[0] == \"cat\":\n",
    "                    self.list_label.append(0)\n",
    "                elif name[0] == \"dog\":\n",
    "                    self.list_label.append(1)\n",
    "\n",
    "        elif self.mode == \"test\":\n",
    "            self.transform = transform_test\n",
    "            directory = directory + \"/sdh_test/\"\n",
    "            for file in os.listdir(directory):\n",
    "                self.list_img.append(directory + file)\n",
    "                self.data_size += 1\n",
    "                name = file.split(sep=\".\")\n",
    "                if name[0] == \"cat\":\n",
    "                    self.list_label.append(0)\n",
    "                elif name[0] == \"dog\":\n",
    "                    self.list_label.append(1)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if self.mode == \"train\":\n",
    "            img = Image.open(self.list_img[item])\n",
    "            label = self.list_label[item]\n",
    "            return self.transform(img), torch.tensor([label])\n",
    "        elif self.mode == \"test\":\n",
    "            img = Image.open(self.list_img[item])\n",
    "            label = self.list_label[item]\n",
    "            return self.transform(img), torch.tensor([label])\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_trained_model():\n",
    "    model = models.resnet34(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(in_features=512, out_features=2, bias=True)\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_train(acces, train_losses):\n",
    "    plt.plot(np.arange(len(acces)), acces)\n",
    "    plt.title('train acc')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(np.arange(len(train_losses)), train_losses)\n",
    "    plt.title('train loss')\n",
    "    plt.show()\n",
    "\n",
    "def plot_image_test(acces, test_losses):\n",
    "    plt.plot(np.arange(len(acces)), acces)\n",
    "    plt.title('test acc')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(np.arange(len(test_losses)), test_losses)\n",
    "    plt.title('test loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    train_image_data_set = CatDogProcessor(\"train\", image_path)\n",
    "    train_data = DataLoader(train_image_data_set, batch_size=16, shuffle=True)\n",
    "    print(\"train_data loaded\", len(train_data))\n",
    "\n",
    "    test_image_data_set = CatDogProcessor(\"test\", image_path)\n",
    "    test_data = DataLoader(test_image_data_set, batch_size=16, shuffle=True)\n",
    "    print(\"train_data loaded\", len(test_data))\n",
    "\n",
    "    model = pre_trained_model()\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = sgd.SGD(model.fc.parameters(), lr=0.001,momentum=0.9)\n",
    "\n",
    "    train_losses = []\n",
    "    train_acces = []\n",
    "    test_losses = []\n",
    "    test_acces = []\n",
    "\n",
    "    for i in range(100):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        model.train()\n",
    "        for im, label in train_data:\n",
    "            # 前向传播\n",
    "            im = im.cuda()\n",
    "            label = label.cuda()\n",
    "            label = label.squeeze()\n",
    "            out = model(im)\n",
    "            loss = criterion(out, label)\n",
    "\n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 记录误差\n",
    "            train_loss += loss.item()\n",
    "            # 计算分类的准确率\n",
    "            _, pred = torch.max(out, 1)\n",
    "            num_correct = (pred == label).sum().item()\n",
    "            acc = num_correct / im.shape[0]\n",
    "            train_acc += acc\n",
    "        train_losses.append(train_loss / len(train_data))\n",
    "        train_acces.append(train_acc / len(train_data))\n",
    "\n",
    "        test_loss = 0\n",
    "        test_acc = 0\n",
    "        model.eval()\n",
    "        for im_test, label_test in test_data:\n",
    "            # 前向传播\n",
    "            im_test = im_test.cuda()\n",
    "            label_test = label_test.cuda()\n",
    "            label_test = label_test.squeeze()\n",
    "\n",
    "            out_test = model(im_test)\n",
    "            loss_test = criterion(out_test, label_test)\n",
    "\n",
    "            # 记录误差\n",
    "            test_loss += loss_test.item()\n",
    "            # 计算分类的准确率\n",
    "            _, pred_test = torch.max(out_test, 1)\n",
    "            num_correct_test = (pred_test == label_test).sum().item()\n",
    "            acc_test = num_correct_test / im_test.shape[0]\n",
    "            test_acc += acc_test\n",
    "\n",
    "        test_losses.append(test_loss / len(test_data))\n",
    "        test_acces.append(test_acc / len(test_data))\n",
    "\n",
    "        print(\"epoch: %d, train loss: %.6f, train acc: %.6f, test loss: %.6f, test acc: %.6f\" % (\n",
    "            i, train_loss / len(train_data), train_acc / len(train_data), test_loss / len(test_data),\n",
    "            test_acc / len(test_data)))\n",
    "\n",
    "    print(\"train and test-----------------Done!\")\n",
    "\n",
    "    plot_image_train(train_acces, train_losses)\n",
    "    plot_image_test(test_acces, test_losses)\n",
    "\n",
    "    torch.save(model.state_dict(), \"model4.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./demo35.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 关于卷积神经网络的原型的说明 \n",
    "(1) 详细原理和网络结构参考论文，原始论文自行搜索。   \n",
    "(2) 关于网络模型的coding，可以从头构建，遇到问题可以参考GitHub中的相关内容。   \n",
    "(3) 更直接的方法，B站看大神的视频。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
